{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feature_extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65ac393adc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeature_Extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFeature_Extraction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'feature_extraction'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "File:          Feature_Extraction.py\n",
    "Author:        Alex Cui\n",
    "Last Modified:\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "from feature_extraction import Feature_Extraction\n",
    "\n",
    "class Feature_Extraction:\n",
    "\n",
    "    def __init__(self, img):\n",
    "        \"\"\"Initializes feature extraction elements by \n",
    "        taking in the path of the image to be processed\n",
    "        \"\"\"\n",
    "        self.image = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "        self.scale_percent = 20\n",
    "        self.detector = cv2.ORB_create(nfeatures=100000, scoreType=cv2.ORB_FAST_SCORE)\n",
    "        self.yellow_lower = np.array([22,60,200],np.uint8)\n",
    "        self.yellow_upper = np.array([60,255,255],np.uint8)\n",
    "\n",
    "    def denoise_real_image(self):\n",
    "        \"\"\"Denoise the image before running feature extraction\n",
    "        \"\"\"\n",
    "\n",
    "        #resize image to the value of scale_percent\n",
    "        width = int(self.image.shape[1] * self.scale_percent / 100)\n",
    "        height = int(self.image.shape[0] * self.scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        self.image = cv2.resize(self.image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        #Denoise the image\n",
    "        self.image = cv2.fastNlMeansDenoisingColored(self.image, None, 7, 21, 50, 10)\n",
    "\n",
    "    def ignore_above(self):\n",
    "        \"\"\"Ignore noises outside the field\n",
    "        \"\"\" \n",
    "\n",
    "        mask = self.__compute_mask()\n",
    "        x = self.__get_highest(mask)\n",
    "        mask[x:, :] = 255\n",
    "        mask[:x, :] = 0\n",
    "        self.image = cv2.bitwise_and(self.image, self.image, mask = mask)\n",
    "\n",
    "    def __compute_mask(self):\n",
    "        \"\"\"Private method that computes mask\n",
    "        \"\"\"\n",
    "\n",
    "        #Create yellow_mask\n",
    "        hsv = cv2.cvtColor(self.image, cv2.COLOR_RGB2HSV)\n",
    "        yellow_mask = cv2.inRange(hsv, self.yellow_lower, self.yellow_upper)\n",
    "        return yellow_mask\n",
    "\n",
    "    def __get_highest(self, mask):\n",
    "        \"\"\"Private method that computes the height above which \n",
    "        everything is ignored\n",
    "        \"\"\"\n",
    "        for i in range (mask.shape[0]):\n",
    "            s = np.sum(mask[i])\n",
    "            if (s >= 255 * mask.shape[1]):\n",
    "                return i\n",
    "\n",
    "    def detect_features(self):\n",
    "        \"\"\"Detect features\n",
    "        \"\"\"       \n",
    "        # find keypoints\n",
    "        kp = self.detector.detect(self.image, None)\n",
    "        kp, des = self.detector.compute(self.image, kp)\n",
    "        k = cv2.drawKeypoints(self.image, kp, None, color=(0,0,255))\n",
    "        self.image = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = '../PF_Images/real_images_input/r_3.png'\n",
    "s_path = '../PF_Images/simulated_images_input/s_3.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im1 = Feature_Extraction(path1)\n",
    "im1.image = im1.image[60: 410, 150: 510]\n",
    "im2 = Feature_Extraction(path2)\n",
    "im2.image = im2.image[60: 410, 150: 510]\n",
    "im3 = Feature_Extraction(path3)\n",
    "im3.image = im3.image[60: 410, 150: 510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp1 = orb.detect(im2.image, None)\n",
    "kp1, des1 = orb.compute(im2.image, kp1)\n",
    "\n",
    "kp2 = orb.detect(im3.image, None)\n",
    "kp2, des2 = orb.compute(im3.image, kp2)\n",
    "\n",
    "if type(des1) != np.float32:\n",
    "    des1 = np.float32(des1)\n",
    "    \n",
    "if type(des2) != np.float32:\n",
    "    des2 = np.float32(des2)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "flann = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "matches = flann.knnMatch(track2.previous_track.raw_descriptor,track2.raw_descriptor, 2)\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)\n",
    "        \n",
    "#-- Draw matches\n",
    "img1 = im2.image\n",
    "img2 = im3.image\n",
    "\n",
    "good\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
    "cv2.drawMatches(img1, kp1, img2, kp2, good, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "#-- Show detected matches\n",
    "plt.imshow(img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # find keypoints for current track\n",
    "        kp1 = track2.previous_track.raw_keypoints\n",
    "        des1 = track2.previous_track.raw_descriptor\n",
    "\n",
    "        # find keypoints for previous track\n",
    "        kp2 = track2.raw_keypoints\n",
    "        des2 = track2.raw_descriptor\n",
    "            \n",
    "        if type(des1) != np.float32:\n",
    "            des1 = np.float32(des1)\n",
    "\n",
    "        if type(des2) != np.float32:\n",
    "            des2 = np.float32(des2)\n",
    "                \n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                            table_number = 6, # 12\n",
    "                            key_size = 12,     # 20\n",
    "                            multi_probe_level = 1) #2\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "        flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "        matches = flann.knnMatch(des1,des2, k=2)\n",
    "\n",
    "        #Filter matches using the Lowe's ratio test\n",
    "        ratio_thresh = 0.7\n",
    "        good_matches = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                good_matches.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
